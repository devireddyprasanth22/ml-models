{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "Linear regression is a statistical method that models a relationship between s dependent variables and one or more independant variables\n",
    "\n",
    "**One independant variable**\n",
    "\n",
    "`y = mx + c` where `y` can be house prices and `x` can be house size\n",
    "\n",
    "**Multiple independant variables**\n",
    "\n",
    "`y = w1x1 + w2x2 .... + w6x6 + b` where `y` is the house prices, `x1, x2..` are features like house size, number of bedrooms and distance to city center, and `w1,w2...` are weights which determine the influence of each feature and `b` is the bias, which adjusts the baseline prediction (shifts up or down without changing slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function (MSE - cost function)\n",
    "Minimise MSE to get the best weight and bias\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Where,\n",
    "\n",
    "$ N $ is the number of data points,\n",
    "\n",
    "$ y_i $ is the actual value we are trying to predict,i.e, the target variable,\n",
    "\n",
    "$ hat{y}_i $ is the predicted value from the regression equation\n",
    "\n",
    "MSE measures how far the predictions are from actual values. A smaller MSE means a better fit.\n",
    "\n",
    "### Side Note\n",
    "New terms I learnt were loss function, cost function, and objective function\n",
    "* **Loss function** is defined on data point, prediction and label and measures the penalty (Squared loss, hinge loss, 0/1 loss)\n",
    "\n",
    "* **Cost function** is a bit more general, it is a sum of loss functions over your training set plus some model complexity penalty (regularization) (MSE, SVM cost function)\n",
    "\n",
    "* **Objective function** is the most general term for any function that is optimized during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Optimation (MSE reductions)\n",
    "This is an iterative algo that updates weight to minimize loss\n",
    "\n",
    "$$\n",
    "w_j = w_j - {\\alpha} \\frac{\\partial MSE}{\\partial w_j}\n",
    "$$\n",
    "\n",
    "and for bias,\n",
    "\n",
    "$$\n",
    "b = b - {\\alpha} \\frac{\\partial MSE}{\\partial b}\n",
    "$$\n",
    "\n",
    "where $ {\\alpha} $ is the learning rate, and the partial function is the gradient of the cost function.\n",
    "\n",
    "Gradient descent moves downhill in the cost function to find the optimal weight and bias (local minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Gradient partial\n",
    "\n",
    "For biases,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial b} = \\frac{-2}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "For weights,\n",
    "\n",
    "$$\n",
    "\\frac{\\partial MSE}{\\partial w_j} = \\frac{-2}{N} \\sum_{i=1}^{N} x_i (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Here $\\hat{y}_i$ is equal to ${x_i}{W} + {b}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Possible functions include, cost_function(), compute_gradients() (the partial derivative), grad_desc() and a predict() for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/dp/.pyenv/versions/3.10.12/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Generate random data\n",
    "X, y = datasets.make_regression(n_samples=300, n_features=1, noise=20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (1158231363.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    def compute_grad(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression:\n",
    "    def __init_(self, learning_rate=0.01, epochs=100, batch_size=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "    def cost_function(self,y, y_pred):\n",
    "        return np.mean((y - y_pred) **2) # for a single data point, will be used in a loop to iterate over all points\n",
    "    \n",
    "    def compute_grad(self, X, y, y_pred):\n",
    "        error = y - y_pred\n",
    "\n",
    "        db = -2 * np.mean(error) # np.mean handles over N samples, can substitute with len(X)\n",
    "        dW = -2 * np.mean(X.T.dot(error)) # Transpose X to fit vector of error\n",
    "\n",
    "        return db, dW\n",
    "        \n",
    "    def grad_desc(self, epochs, batch_size):\n",
    "    def predict(self):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
